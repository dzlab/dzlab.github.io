---
layout: post
comments: true
title: Pinterest's Wide Column Database in Python with RocksDB
excerpt: Building a simplified version of Pinterest's a Wide Column Database in Python with RocksDB
categories: database
tags: [python,rocksdb]
toc: true
img_excerpt:
---


In a recent article on [Pinterest Engineering Blog](https://medium.com/pinterest-engineering/building-pinterests-new-wide-column-database-using-rocksdb-f5277ee4e3d2), they desribed in a details how they implemented in C++ a RocksDB-based distributed wide column database called **Rockstorewidecolumn**. While their system tackles petabytes and millions of requests per second with a distributed architecture, the core concepts of mapping a wide column data model onto a key-value store like RocksDB are fascinating.

This article explore how to implement a simpler, single-instance version of Pinterest's **Rockstorewidecolumn** in Python using the power and efficiency of RocksDB.


### What's a Wide Column Database, Anyway?

Think beyond traditional relational tables with fixed schemas. A wide column database offers:

*   **Rows:** Each identified by a unique `row_key`.
*   **Flexible Columns:** Each row can have a different set and number of columns. No predefined schema for all rows!
*   **Columnar Data:** Data is organized by columns within a row.
*   **Versioned Cells:** Often, values within a column can have multiple versions, typically timestamped.

This model is great for use cases like user profiles (where users have varying attributes), time-series data, or, as Pinterest showed, storing user event sequences.

### The Challenge: From Wide Columns to Simple Keys & Values

RocksDB is an incredibly fast embedded key-value store. It doesn't inherently understand "rows," "columns," or "versions." It just knows keys and values, both of which are byte strings. Our main task is to cleverly design a **key structure** that lets us represent our wide column model.

### Our Data Model & RocksDB Key Design

1.  **Logical View:**
    *   **Row Key:** Uniquely identifies a row (e.g., `user123`).
    *   **Column Name:** Identifies a specific attribute within a row (e.g., `email`, `last_login_event`).
    *   **Timestamp:** When this specific piece of data was recorded (e.g., milliseconds since epoch).
    *   **Value:** The actual data for that row, column, and timestamp.

2.  **Storage View (The RocksDB Key):**
    To store a specific cell (a value for a given row, column, and time), we'll concatenate these elements into a single RocksDB key. A separator (like the null byte `\x00`) is crucial.

    `RocksDB_Key = row_key_bytes + SEPARATOR + column_name_bytes + SEPARATOR + encoded_timestamp_bytes`

    The `RocksDB_Value` will simply be the `column_value_bytes`.

3.  **The Timestamp Trick for Versioning:**
    We want to retrieve the latest versions of a column first. RocksDB sorts keys lexicographically in ascending order. To get descending order for timestamps:
    *   Use integer timestamps (e.g., milliseconds since epoch).
    *   Store `MAX_POSSIBLE_TIMESTAMP - actual_timestamp`.
    *   Pack this inverted timestamp as a fixed-length, big-endian byte string (e.g., using Python's `struct.pack('>Q', inverted_timestamp)` for an 8-byte unsigned integer).

    This way, newer (smaller inverted) timestamps will sort before older ones.


```
+----------------------+-----------------+-------------------+-----------------+-----------------------+-----------------+-------------------------------------------+
| dataset_name_bytes   | KEY_SEPARATOR   | row_key_bytes     | KEY_SEPARATOR   | column_name_bytes     | KEY_SEPARATOR   | timestamp_bytes                           |
+----------------------+-----------------+-------------------+-----------------+-----------------------+-----------------+-------------------------------------------+
| (String as UTF-8)    | (Null Byte `\0`)| (String as UTF-8) | (Null Byte `\0`)| (String as UTF-8)     | (Null Byte `\0`)| (8-byte uint64, Big-Endian, Inverted)   |
+----------------------+-----------------+-------------------+-----------------+-----------------------+-----------------+-------------------------------------------+

```

### A Python Implementation Sketch

We'll use the `python-rocksdb` library. Let's outline a `WideColumnDB` class:


**Key Implementation Points:**

*   **`_encode_key` / `_decode_key`:** These are the heart of the system, translating our logical model to and from RocksDB's byte strings.
*   **`put_row`:** Takes a list of items for a row. Each item can optionally specify a timestamp. If not, the current server time is used. All writes for a single `put_row` call are wrapped in a `rocksdb.WriteBatch` for atomicity at the row-key level for that call.
*   **`get_row`:** This is the most complex.
    *   It uses RocksDB's iterators and `seek()` operations.
    *   To get all columns for a row, it seeks to `row_key_bytes + SEPARATOR`.
    *   To get specific columns, it can either iterate and filter or seek to `row_key_bytes + SEPARATOR + column_name_bytes + SEPARATOR`.
    *   It collects up to `num_versions` for each requested column, respecting the (optional) time range.
*   **`delete_row`:** Also uses iterators to find all keys matching the criteria (entire row, specific columns, or even specific versions) and deletes them using a `WriteBatch`.

### Unlocking Wide Column Features

With this key structure, several wide column features become quite natural:

*   **Versioned Values:** Automatically handled by including the timestamp in the key. Each update (even an "overwrite" of a conceptual column) with a new timestamp creates a new, distinct entry in RocksDB.
*   **Time Range Queries:** The `get_row` method can filter versions based on `start_timestamp` and `end_timestamp` by examining the decoded timestamp from the key.
*   **Out-of-Order Updates:** Clients can provide their own timestamps for data, allowing for backfills or event-time recording.
*   **TTL (Time-to-Live):**
    *   **Read-time enforcement:** When reading, check `key_timestamp + configured_ttl < current_timestamp`. If expired, don't return it.
    *   **Physical deletion:** This is trickier for a simple implementation. RocksDB's compactions will eventually remove deleted data. A more advanced system might use RocksDB's compaction filters or a background process to scan and delete expired keys.

### Simplicity's Trade-offs

This Python implementation is a great learning tool and can be surprisingly useful for smaller-scale applications:

*   **Single Instance:** It's not distributed, so no built-in replication, sharding, or high availability like Pinterest's Rockstorewidecolumn.
*   **Basic Compaction:** Relies on RocksDB's default compaction unless you delve into advanced configurations or custom filters for TTL.
*   **Pagination:** The `get_row` example above doesn't include pagination for very wide rows (many columns). This would require returning a "continuation token" (e.g., the last key part processed) for the client to pass in the next request.

### What's Next?

If you were to expand this:

*   **Dataset/Table Management:** Consider using RocksDB's "Column Families" for better logical separation of different datasets (tables) within a single DB instance.
*   **Advanced TTL:** Implement custom compaction filters or background jobs for efficient TTL enforcement.
*   **Robust Pagination:** Add proper marker-based pagination to `get_row`.
*   **Serialization:** Use a more robust serialization format than plain strings for values (e.g., JSON, MessagePack, Protobuf).

### Conclusion

Building a simplified wide column database on top of RocksDB in Python is an achievable and insightful exercise. By carefully designing your key structure, you can map complex data models onto a high-performance key-value store. While it won't rival enterprise-grade distributed systems, it provides a powerful local storage solution and a deeper understanding of how these systems work under the hood.

Happy coding!

## That's all folks

I hope you enjoyed this article, feel free to leave a comment or reach out on twitterÂ [@bachiirc](https://twitter.com/bachiirc).
