---
layout: post
comments: true
title: Setting Up Elastic-based logging stack with Docker Compose
excerpt: Learn how to quickly setup an ELK-based logging stack with Docker Compose.
categories: monitoring
tags: [docker,elastic,kibana]
toc: true
img_excerpt:
---

<img align="left" src="/assets/logos/icons8-docker.svg" width="150" />
<img align="left" src="/assets/logos/elasticsearch.svg" width="120" />
<img align="left" src="/assets/logos/kibana.svg" width="100" />
<img align="center" src="/assets/logos/elastic-beats-logo-vector.svg" width="160" />
<br/>

The ELK (Elasticsearch, Logstash, and Kibana) stack usage have expanded way beyond its original use case of logs aggregation into new use areas like telemetry. 


 is to aggregate logs. However, with the increased usage of ELK and Kubernetes as a pairing the solution can go beyond the aggregation of standard logs and include monitoring and analysis of Kubernetes telemetry data. Therefore, more users are looking at deploying the ELK stack on Kubernetes. Yet, deploying the ELK stack on Kubernetes can be a complex task but with the assistance of Helm charts, the process is much simpler.

This article will highlight why deploying the ELK stack on Kubernetes is beneficial to an organization and outline a configuration guide for deploying the ELK stack on Kubernetes with Helm charts.

## Setup
https://cloud.google.com/kubernetes-engine/docs/how-to/

```shell
$ LOCATION=us-central1-a
$ CLUSTER_NAME=kubetest
```

Use a machine with enough Memory, by default GCP will create a GKE cluster with machine type `e2-medium` which is a medium-sized instance with 2 vCPUs and 4 GB of memory.

```shell
$ gcloud compute machine-types list --filter="$LOCATION"
```

```shell
$ gcloud container clusters create $CLUSTER_NAME \
  --zone $LOCATION \
  --node-locations $LOCATION \
  --machine-type e2-standard-4
```

```shell
$ gcloud container clusters delete $CLUSTER_NAME --location $LOCATION
```

This will create GKE cluster

```
NAME      LOCATION       MASTER_VERSION      MASTER_IP     MACHINE_TYPE   NODE_VERSION        NUM_NODES  STATUS
kubetest  us-central1-a  1.28.8-gke.1095000  34.72.13.154  e2-standard-4  1.28.8-gke.1095000  3          RUNNING
```

```
NAME      LOCATION     MASTER_VERSION      MASTER_IP      MACHINE_TYPE  NODE_VERSION        NUM_NODES  STATUS
kubetest  us-central1  1.28.8-gke.1095000  35.222.39.139  e2-medium     1.28.8-gke.1095000  9          RUNNING

NAME      LOCATION       MASTER_VERSION      MASTER_IP       MACHINE_TYPE   NODE_VERSION        NUM_NODES  STATUS
kubetest  us-central1-a  1.28.8-gke.1095000  34.136.129.131  n4-standard-2  1.28.8-gke.1095000  3          RUNNING
```

0. Install Helm with Homebrew
Run the following Homebrew command to install Helm on your local macOS operating system.

https://helm.sh/docs/intro/install/



## How to Deploy the ELK Stack on Kubernetes with Helm Chats
In this section, we will outline in detail how to deploy the ELK stack on Kubernetes using Helm charts. Before following this configuration guide, it’s important to ensure you have a Kubernetes cluster running and that you have Helm installed on your local machine and Tiller (Helm's server-side component) deployed in your Kubernetes cluster.

1. Add Elastic Helm Charts Repository: Elastic offers official Helm charts for deploying the ELK stack components. By adding the Elastic Helm repository to your Helm configuration, you attain access to these charts.

```shell
$ helm repo add elastic https://helm.elastic.co
"elastic" has been added to your repositories

$ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "elastic" chart repository
Update Complete. ⎈Happy Helming!⎈
```

Create a namespace for installing Elasticsearch
```shell
$ kubectl create namespace monit
namespace/monit created
```

### Elasticsearch
Install Elasticsearch: Elasticsearch is the core of the ELK stack, responsible for storing and indexing log data. When installing Elasticsearch with Helm, you can customize parameters such as the number of replicas (for high availability) and JVM heap size using Helm chart values. Replace with the Kubernetes namespace where you want to deploy Elasticsearch.

```shell
$ helm install elasticsearch elastic/elasticsearch \
  --namespace monit \
  --set replicas=3 \
  --set esJavaOpts="-Xmx512m -Xms512m"
```

1. Watch all cluster members come up.
```shell
$ kubectl get pods --namespace=monit -l app=elasticsearch-master -w
```

After few minutes the different replicates will be ready and the Elasticsearch cluster properly running
```
NAME                     READY   STATUS    RESTARTS   AGE
elasticsearch-master-0   1/1     Running   0          9m20s
elasticsearch-master-1   1/1     Running   0          9m20s
elasticsearch-master-2   1/1     Running   0          9m20s
```

```shell
$ kubectl describe pod elasticsearch-master-0 -n monit
```

```
Events:
  Type     Reason                  Age                From                     Message
  ----     ------                  ----               ----                     -------
  Normal   Scheduled               17m                default-scheduler        Successfully assigned monit/elasticsearch-master-0 to gke-kubetest-default-pool-ddfd6147-mqrr
  Normal   SuccessfulAttachVolume  17m                attachdetach-controller  AttachVolume.Attach succeeded for volume "pvc-b3137a25-241c-4337-89c1-d6e3953440fe"
  Normal   Pulling                 17m                kubelet                  Pulling image "docker.elastic.co/elasticsearch/elasticsearch:8.5.1"
  Normal   Pulled                  17m                kubelet                  Successfully pulled image "docker.elastic.co/elasticsearch/elasticsearch:8.5.1" in 19.341s (19.341s including waiting)
  Normal   Created                 17m                kubelet                  Created container configure-sysctl
  Normal   Started                 17m                kubelet                  Started container configure-sysctl
  Normal   Pulled                  16m                kubelet                  Container image "docker.elastic.co/elasticsearch/elasticsearch:8.5.1" already present on machine
  Normal   Created                 16m                kubelet                  Created container elasticsearch
  Normal   Started                 16m                kubelet                  Started container elasticsearch
  Warning  Unhealthy               15m (x6 over 16m)  kubelet                  Readiness probe failed: Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )
Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )
```

2. Retrieve elastic user's username.

```shell
$ kubectl get secrets --namespace=monit elasticsearch-master-credentials -ojsonpath='{.data.username}' | base64 -d
```

2. Retrieve elastic user's password.

```shell
$ kubectl get secrets --namespace=monit elasticsearch-master-credentials -ojsonpath='{.data.password}' | base64 -d
```

3. Test cluster health using Helm test.

```shell
$ helm --namespace=monit test elasticsearch
```

```
NAME: elasticsearch
LAST DEPLOYED: Tue May 28 11:53:00 2024
NAMESPACE: monit
STATUS: deployed
REVISION: 1
TEST SUITE:     elasticsearch-qsmth-test
Last Started:   Tue May 28 12:05:09 2024
Last Completed: Tue May 28 12:05:12 2024
Phase:          Succeeded
```

### Kibana
Install Kibana: Kibana is the visualization and dashboarding component of the ELK stack. It offers a user-friendly interface for exploring and analyzing log data stored in Elasticsearch. By installing Kibana with Helm, you can quickly deploy and configure it to connect to your Elasticsearch cluster.

```shell
$ helm install kibana elastic/kibana --namespace monit
```

1. Watch all containers come up.

```shell
$ kubectl get pods --namespace=monit -l release=kibana -w
```

Ater few seconds, Kibana will be ready
```
NAME                             READY   STATUS    RESTARTS   AGE
kibana-kibana-8446b87c9f-2vh8g   1/1     Running   0          76s
```

```shell
$ kubectl get svc --namespace=monit -l release=kibana 
NAME            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
kibana-kibana   ClusterIP   10.30.38.169   <none>        5601/TCP   14m
```

3. Retrieve the kibana service account token.
```shell
$ kubectl get secrets --namespace=monit kibana-kibana-es-token -ojsonpath='{.data.token}' | base64 -d
```

#### Access Kibana
Access Kibana: If you configured an Ingress, you can access Kibana via . 

Otherwise, you can use port-forwarding to access it. 

```shell
$ kubectl port-forward service/kibana-kibana :5601 --namespace monit
```

```
Forwarding from 127.0.0.1:51850 -> 5601
Forwarding from [::1]:51850 -> 5601
```

Then, open `http://localhost:51850` in your web browser.


### Logstash
Install Logstash (Optional): Logstash is an optional component used for log ingestion, processing, and enrichment. If you have specific log processing requirements, such as parsing structured logs or applying filters, you can install Logstash using the Elastic Helm chart.

```shell
$ helm install logstash elastic/logstash --namespace monit
```

1. Watch all cluster members come up.

```shell
$ kubectl get pods --namespace=monit -l app=logstash-logstash -w
```

After few seconds, the logstash container will become ready
```
NAME                  READY   STATUS    RESTARTS   AGE
logstash-logstash-0   1/1     Running   0          2m17s
```

### Next steps

- Configure Index Patterns in Kibana: Before visualizing log data in Kibana, you need to define index patterns that specify which Elasticsearch indices to query. Index patterns define the structure of your log data and enable Kibana's powerful search and visualization capabilities.

- Configure Logstash (Optional): If you installed Logstash, configure Logstash pipelines to ingest and process your logs. You can define Logstash configuration files and mount them as ConfigMaps or use other methods for configuration management. http://localhost:51850/app/integrations/detail/logstash/overview

- Monitor Elasticsearch and Kibana: Monitor Elasticsearch and Kibana using built-in metrics or integrate with external monitoring solutions like Prometheus and Grafana for comprehensive observability.

I hope you enjoyed this article, feel free to leave a comment or reach out on twitter [@bachiirc](https://twitter.com/bachiirc).
